# ACOL-GAN
## Abstract
Clustering is one of the research hotspots of deep learning. Recently, deep generative models provide a new way to achieve clustering. However, from all the proposed models, the performance of the clustering variants based on the Variational Autoencoder(VAE) are superior than that based on the Generative Adversarial Network (GAN), which is mainly because the former allows the data to be multi-mode in latent space but the latter does not do so, making the boundaries of different classes obscure and difficult to distinguish. In this paper, we propose a new GAN-based clustering model named Auto-clustering Output Layer Generative Adversarial Network(ACOL-GAN), which replaces the normal distribution that standard GAN relied on with Gaussian mixture distribution generated by sampling networks and adopts the Auto-clustering Output Layer(ACOL) as the output layer in discriminator. Due to Graph-based Activity Regularization(GAR) terms, softmax nodes of parent-classes are specialized as the competition between each other occurs during training. The experimental results show that ACOL-GAN is superior to most unsupervised clustering algorithms on MNIST, USPS and Fashion-MNIST datasets. 


## Comparison
.<img src="https://github.com/wusongyuan/ACOL-GAN/blob/master/ACOL-GAN/rs_image/acc.png"/>
The ACOL-GAN algorithm was compared to the most advanced clustering methods. As shown in Table 1, the ACOL-GAN clustering algorithm is better than or equal to other algorithms in most cases, and the performance on the Fashion-MNIST dataset is the best in the recorded algorithm clustering results. 

## Visualization
.<img src="https://github.com/wusongyuan/ACOL-GAN/blob/master/ACOL-GAN/rs_image/visualization.png"/>
The latent representation of the MNIST data set is visualized by t-SNE[5]. ACOL-GAN can quickly capture the data distribution of the MNIST dataset in the latent space and make the actual data to fit the specified Gaussian mixture for fast clustering. And only 5 epochs are needed to achieve different boundaries in the latent space. 

## Convergence curve
.<img src="https://github.com/wusongyuan/ACOL-GAN/blob/master/ACOL-GAN/rs_image/acc.png"/>
The clustering accuracy curve of MNIST dataset increases rapidly, reaching more than 90% with just 10 epochs. This shows that the ACOL-GAN model can converge quickly, and the advantages of the k manifold model. Moreover, ACOL-GAN is no need for pre-training and the convergence speed is faster and the accuracy is higher compared with other clustering models. 
